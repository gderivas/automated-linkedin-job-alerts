# AUTOGENERATED! DO NOT EDIT! File to edit: linkedin.ipynb.

from dotenv import load_dotenv
import os
import re

import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.keys import Keys

import time
from datetime import date, datetime

import pyautogui as pygui
import webbrowser
import configargparse

def lkd_login():

    options = webdriver.ChromeOptions()
    options.add_experimental_option('excludeSwitches', ['enable-logging'])
    #service = Service(ChromeDriverManager().install())
    #driver = webdriver.Chrome(service=service)
    
    driver = webdriver.Chrome(options=options)

    driver.get("https://www.linkedin.com/login")

    username = driver.find_element('id','username')
    password = driver.find_element('id','password')

    load_dotenv()

    MAIL = os.getenv('EMAIL')
    PASSWORD = os.getenv('PASSWORD')

    username.send_keys(MAIL)
    password.send_keys(PASSWORD)

    password.send_keys(Keys.RETURN)
    return driver

def get_flexibily_url(flexibility):
    flexibilty_url = 'WT=2%2C1%2C3'
    return flexibilty_url

def get_url(job_info,args):
    position = "&keywords='" + "%20".join(job_info.split(' '))
    root = 'https://www.linkedin.com/jobs/search/?currentJobId=4035202295&distance=25&f_'
    flexibility_url = get_flexibily_url(args.flexibility)
    geo_id = '&geoId=' + args.location 
    end = '&origin=JOB_SEARCH_PAGE_JOB_FILTER&sortBy=DD'
    url = root + flexibility_url + geo_id + position + end
    #url = "https://www.linkedin.com/jobs/search/?currentJobId=4035202295&distance=25&f_WT=2&geoId=105646813&keywords=Business%20Data%20Analyst&origin=JOB_SEARCH_PAGE_JOB_FILTER&sortBy=DD"
    return url

def get_data(driver,url):  
    driver.get(url)
    time.sleep(5)
    html = driver.page_source
    time.sleep(5)
    soup = BeautifulSoup(html, 'html.parser')
    time.sleep(5)
    mydivs = soup.find_all("div", {"class": "flex-grow-1 artdeco-entity-lockup__content ember-view"})
    return mydivs

def get_loc(info2):
    tmp_loc = str(info2[0]).split('<!-- -->')[1].split('·')
    if len(tmp_loc) == 1:
        loc = tmp_loc[0]
    else:
        loc = tmp_loc[1]
    return loc

def get_info(mydiv):
    info1 = mydiv.find_all("span", {"class": "visually-hidden"})
    puesto = str(info1[0]).split('<!-- -->')[1]
    puesto = cleaning(puesto)
    info2 = mydiv.find_all("div", {"class": "artdeco-entity-lockup__caption ember-view"})
    info3 = mydiv.find_all("span", {"class": "job-card-container__primary-description"})
    empresa = str(info3[0]).split('<!-- -->')[1].split('·')[0]
    empresa = cleaning(empresa)
    loc = get_loc(info2)
    loc = cleaning(loc)
    a = mydiv.findAll('a')
    link = str(a).split('href=')[1].split(' ')[0].split(';')[0]
    link = 'www.linkedin.com' + link[1:]
    job_id = link.split('/')[3]
    return puesto, empresa, loc, link, job_id

def cleaning(string):
    string = string.replace('&amp;','&')
    string = string.replace('with verification','')
    string = re.sub(r'<[^<]*>?','',string)
    return string

def make_search(driver,url,job_des, args):
    print(f'>> New {job_des} Search!\n')
    mydivs = get_data(driver,url)
    print('..  Info retrieved.')
    if os.path.isfile(args.export_file):
        df = pd.read_excel('job_list.xlsx',converters={'ID':str})
    else:
        print('No export file found!')
        df = pd.DataFrame({'ID':[],'Búsqueda':[],'Fecha':[],'Puesto':[],'Empresa':[],'Localización':[],'Link':[]},index=[0])
    today = datetime.now().strftime('%m/%d/%Y %H:%m')
    for mydiv in mydivs:
        puesto, empresa, loc, link, job_id = get_info(mydiv)
        if str(job_id) not in df.ID.values:
            print('... New Position!')
            message = f'{puesto} en {empresa}'
            pressed = pygui.confirm(text=message,buttons=['go to position','cancel'],timeout=100000)
            if pressed == 'go to position':
                CHROME_PATH = os.getenv('CHROME_PATH')
                webbrowser.get(CHROME_PATH).open(link)
            #win32ui.MessageBox(message, "New Position!")
            tmp_df = pd.DataFrame({'ID':str(job_id),'Búsqueda':job_des,'Fecha':today,'Puesto':puesto,'Empresa':empresa,'Localización':loc,'Link':link},index=[0])
            df = pd.concat([df,tmp_df])
            print(f'Puesto: {puesto}, Empresa: {empresa}, Localización: {loc}, Job ID:{job_id}')

    if args.export:
        print('... Writing to disk!\n')
        df.to_excel('job_list.xlsx', index=False)


def get_args():
    parser = configargparse.ArgParser()

    parser.add_argument("-k", "--keywords", nargs='+', default=['Rey'],
                        help="Key words of job position")
    
    parser.add_argument("-f", "--flexibility", type=str, default="all",
                        help="Select the job flexibility (remote, hybrid or presence)")
    
    parser.add_argument("-l", "--location", type=str, default="105646813",
                        help="Select the location ID")
    
    parser.add_argument("-e", "--export", action='store_true', default=False,
                        help="Export new positions to file")

    parser.add_argument("-ef", "--export_file", type=str, default="job_list.xlsx",
                        help="Select the path of the export file")
    
    parser.add_argument("-w", "--wait_time", type=int, default=15,
                        help="Select the waiting time between searches in minutes")
    
    args = parser.parse_args()
    
    return args

